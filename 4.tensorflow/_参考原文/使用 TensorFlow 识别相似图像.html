<!DOCTYPE html>
<!-- saved from url=(0080)https://douglasduhaime.com/posts/identifying-similar-images-with-tensorflow.html -->
<html lang="zh-CN" class="translated-ltr"><script async="" src="./使用 TensorFlow 识别相似图像_files/analytics.js"></script><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
<meta http-equiv="x-ua-compatible" content="ie=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="google-site-verification" content="eYLUlW-Cr452cLvMYOYoqYtyqArzYvYYryVJV1jsV5o">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@">
<meta name="twitter:creator" content="@">
<meta property="og:url" content="http://douglasduhaime.com/posts/identifying-similar-images-with-tensorflow.html">

  <meta name="og:title" content="Identifying Similar Images with TensorFlow">


  <meta name="description" content="Detecting similar images in large data collections with Tensorflow and Scikit Learn" s="" tsne="" implementation.="" '="">
  <meta name="og:description" content="Detecting similar images in large data collections with Tensorflow and Scikit Learn" s="" tsne="" implementation.="" '="">


  <meta property="og:image" content="http://douglasduhaime.com/assets/posts/similar-images/similar-images-banner.jpg">


  <meta http-equiv="cache-control" content="no-cache, no-store, must-revalidate">
  <meta http-equiv="pragma" content="no-cache">
  <meta http-equiv="expires" content="0">

    <title>使用 TensorFlow 识别相似图像</title>
    <link rel="icon" href="https://douglasduhaime.com/assets/images/favicon.ico" type="image/x-icon">
    
    <style>/*! normalize.css v3.0.2 | MIT License | git.io/normalize */@import url("https://fonts.googleapis.com/css?family=Montserrat:400,500");html{font-family:sans-serif;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}body{margin:0}article,aside,details,figcaption,figure,footer,header,hgroup,main,menu,nav,section,summary{display:block}audio,canvas,progress,video{display:inline-block;vertical-align:baseline}audio:not([controls]){display:none;height:0}[hidden],template{display:none}a{background-color:transparent}a:active,a:hover{outline:0}abbr[title]{border-bottom:1px dotted}b,strong{font-weight:bold}dfn{font-style:italic}h1{font-size:2em;margin:0.67em 0}mark{background:#ff0;color:#000}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sup{top:-0.5em}sub{bottom:-0.25em}img{border:0}svg:not(:root){overflow:hidden}figure{margin:1em 40px}hr{-moz-box-sizing:content-box;box-sizing:content-box;height:0}pre{overflow:auto}code,kbd,pre,samp{font-family:monospace, monospace;font-size:1em}button,input,optgroup,select,textarea{color:inherit;font:inherit;margin:0}button{overflow:visible}button,select{text-transform:none}button,html input[type="button"],input[type="reset"],input[type="submit"]{-webkit-appearance:button;cursor:pointer}button[disabled],html input[disabled]{cursor:default}button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0}input{line-height:normal}input[type="checkbox"],input[type="radio"]{box-sizing:border-box;padding:0}input[type="number"]::-webkit-inner-spin-button,input[type="number"]::-webkit-outer-spin-button{height:auto}input[type="search"]{-webkit-appearance:textfield;-moz-box-sizing:content-box;-webkit-box-sizing:content-box;box-sizing:content-box}input[type="search"]::-webkit-search-cancel-button,input[type="search"]::-webkit-search-decoration{-webkit-appearance:none}fieldset{border:1px solid #c0c0c0;margin:0 2px;padding:0.35em 0.625em 0.75em}legend{border:0;padding:0}textarea{overflow:auto}optgroup{font-weight:bold}table{border-collapse:collapse;border-spacing:0}td,th{padding:0}*{margin:0;padding:0}html{height:100%;overflow-y:scroll;-webkit-tap-highlight-color:transparent}body{font-family:'Montserrat', sans-serif;color:#222;font-size:1em;font-weight:400;line-height:1.5em;letter-spacing:.02em}.container{width:100%;max-width:750px;display:inline-block;text-align:left;padding:40px;box-sizing:border-box}h1,h2,h3,h4{margin:20px 0 10px;text-align:center}h1{color:#d53a26}h2{font-size:1.35em;line-height:1.35em}a{text-decoration:none;color:#d53a26;font-weight:500}p{margin:15px 0;line-height:1.75em}.center-text{text-align:center}.container img{max-width:100%;margin:20px auto;display:block}img.large{width:auto}img.medium{width:60%}img.small{width:200px}.background-image{background-repeat:no-repeat;background-position:center center;-webkit-background-size:cover;-moz-background-size:cover;-o-background-size:cover;background-size:cover}.inline-trio{display:table;width:100%;border-spacing:5px}.inline-trio .default-image{width:33%;display:table-cell;padding:0 4px;box-sizing:border-box}.grayscale{-webkit-filter:grayscale(1);filter:grayscale(1)}.header{height:200px;width:100%;box-shadow:2px 1px 5px #888888;overflow:hidden;background-color:#ffecb3}@media (max-width: 500px){.header{height:120px}}.header .background-image{width:100%;height:100%}body{min-height:100%;display:flex;flex-direction:column}#content{flex:1;display:flex;flex-direction:column}.home,.post{flex:1;max-width:100%;overflow:hidden}.footer{height:50px;display:table;width:100%;color:#fff;overflow:hidden;background:#4c4c4c;text-align:center}.footer-icon{width:15px;height:15px;margin:12px 1px 0;background:#ededed;padding:6px;border-radius:100%;display:inline-block;vertical-align:top}.footer .square-image{display:inline-block;vertical-align:top}.footer .square-image img,.home-footer .square-image img{border-radius:0;padding:1px 1px;width:13px;vertical-align:top;position:relative;background:none;display:inline-block;margin:0}.footer .footer-icon:hover{opacity:0.8}.home-icon{height:34px;width:34px;background:#d53a26;fill:#fff;position:fixed;top:20px;right:20px;border-radius:100%;cursor:pointer;box-shadow:1px 1px 5px #525151;z-index:10}.home-icon a{display:block;width:50px;height:50px;margin-left:-8px;margin-top:-8px}.home-icon img{height:22px;margin:14px}.home{height:100%}.home .container{display:block;margin:40px auto;width:80%;max-width:980px;padding:0}.home h1{font-size:45px;line-height:1.2em;color:#454545;margin:0 0 0 -3px;text-align:left;font-weight:100;letter-spacing:-1px}.home h2{text-align:left;font-weight:100;font-size:31px;margin:0 0 25px;color:#444}.home .about{color:#666;margin-bottom:15px;font-size:17px;line-height:22px}@media (max-width: 600px){.home .container{width:93%}.home h1{font-size:31px}.home .about{font-size:16px;line-height:16px;color:#999;font-weight:400;margin-top:5px}}@media (max-width: 400px){.home .about{font-size:13px;line-height:14px;color:#999;margin-top:3px}}.home-posts,.home-projects{text-align:left;display:inline-block;padding-top:25px;width:700px}.home-post{width:100%}.home-post,.home-project{margin-bottom:35px}.home-post .title{display:inline-block;font-size:17px;line-height:17px;color:#666;margin:10px 0 4px;transition:color .2s}.home-post .date{display:block;color:#999;font-size:13px;line-height:14px}.home-post a{text-decoration:none;display:block;font-size:1.2em;color:#555;font-weight:400}.home-post .post-thumbnail,.home-project .project-image{background-color:#aaa;border:1px solid #757575;box-sizing:border-box}.home-post .post-thumbnail{width:100%;height:0;padding-bottom:11%;margin:0;background-size:cover;background-position:left center;background-repeat:no-repeat}.home-post:hover .title{color:#d53a26}@media (max-width: 874px){.home-posts,.home-projects{width:100%;padding-top:15px}}@media (min-width: 875px){.home-post .title{max-width:600px}.home-post .date{float:right;margin-top:12px}}@media (max-width: 600px){.home-post .title{font-size:16px}}.home-project{color:#444;text-align:left}.home-project .project-image{width:100%;background-position:top center;position:relative;padding-bottom:41%;background-size:cover;background-position:center center}.home-project .project-image img{margin:0}.home-project .project-title{font-weight:300;font-size:22px;margin:7px 0 0;color:#444;display:inline-block}.home-project .project-tech div{display:inline-block;margin-right:8px;color:#aaa;font-size:14px}.home-project .project-links{display:inline-block;background:rgba(0,0,0,0.65);color:#fff;position:absolute;bottom:0;right:0;padding:1px 7px;width:auto;max-width:110px;white-space:nowrap}.home-project .project-links a{color:#fff}.home-project .project-text p{line-height:1.4em;font-weight:300;margin:0}.home-project .project-categories{float:right;margin-right:-10px}.home-footer{width:100%;overflow:auto}.home-footer a{float:left;margin-right:2px}.home-footer .footer-icon{background:#4c4c4c;margin-top:0}noscript{position:fixed;top:0;width:100%;text-align:center;padding:5px 0;background:#d61010;color:#fff;font-weight:500;font-size:17px;z-index:100}.post{height:100%;width:100%}.post .container{display:block;margin:0 auto}@media (max-width: 520px){.post .container{padding:10px}}.post .title{font-size:1.8em;font-weight:500;margin:0;text-align:center;color:#d53a26;line-height:1.2em}.post .date{color:#777;font-size:0.9em;text-align:center;margin-top:4px}pre{margin:0;padding:20px}code{height:100%;width:100%;display:block;box-sizing:border-box}p code{display:inline-block;width:auto;height:auto;padding:0 4px;margin:0;line-height:inherit;background:#272822;border-radius:3px;color:#eee}figure.highlight{margin:0;padding:0;border-radius:4px}table{margin:0 auto;background:#eeeeef}td,th{padding:7px 17px}table thead,table tr{background:#f5f5f5}table tr:nth-child(2n){background:#e4e4e4}select{padding:6px 28px 6px 6px;box-sizing:border-box;border:1px solid #ccc;border-radius:4px;-webkit-appearance:none;-moz-appearance:none;appearance:none;-webkit-user-select:none;-moz-user-select:-moz-none;-ms-user-select:none;user-select:none;cursor:pointer;background:transparent;background-image:url(/assets/images/icons/caret.png);background-repeat:no-repeat;background-size:23px;background-position:95% 8px}input[type=text]{line-height:normal;height:20px;padding:6px;border-radius:4px;border:none;background:#efefef;margin:5px 0}textarea{overflow:auto;outline:none;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;resize:none;padding:6px;border-radius:4px;border:1px solid #ccc}button,input[type=submit],input[type=button],input[type=reset]{cursor:pointer;padding:7px 20px;background:#d53a26;color:#fff;border:none;border-radius:4px;display:table;margin:0 auto;box-shadow:0 3px 1px -2px rgba(0,0,0,0.2),0 2px 2px 0 rgba(0,0,0,0.14),0 1px 5px 0 rgba(0,0,0,0.12)}form button{margin-top:10px}button:disabled,input:disabled{opacity:0.6}ul{list-style-type:none}.well{min-height:20px;padding:19px;margin-bottom:20px;background-color:#f5f5f5;border:1px solid #e3e3e3;border-radius:4px;display:table;margin:0 auto}form{display:table;margin:25px auto;border-radius:4px}fieldset{padding:18px 20px;border-radius:4px}label{margin:5px}.click-to-interact{position:relative;display:block}.click-to-interact::before{content:'';position:absolute;top:0;right:0;bottom:0;left:0;background:rgba(0,0,0,0.5);z-index:10;color:#fff;opacity:0;transition:opacity 0.3s}.click-to-interact::after{content:'Click to enter →';display:block;width:100%;color:#fff;position:absolute;top:50%;margin-top:-0.5em;text-align:center;z-index:11;font-size:24px;opacity:0}.click-to-interact:hover::before,.click-to-interact:hover::after{opacity:1}.click-to-interact img{display:block}.image-grid{width:100%;margin:20px 0}.image-grid .row{display:table;width:100%}.image-grid .grid-item{width:33%;padding-bottom:33%;display:table-cell;overflow:auto;position:relative;z-index:-1}.image-grid .grid-item .cell{margin:4px;box-sizing:border-box;position:absolute;top:0;right:0;bottom:0;left:0}.duotone{-webkit-filter:url(#header-duotone);filter:url(#header-duotone)}.duotone-invert{-webkit-filter:invert(100%) url(#header-duotone);filter:invert(100%) url(#header-duotone)}.fixed-background{background-attachment:fixed}.lightbox{display:none;position:fixed;z-index:999;width:100%;height:100%;text-align:center;top:0;left:0;background:rgba(0,0,0,0.8)}.lightbox img{max-width:90%;max-height:80%;position:fixed;top:50%;left:50%;transform:translateY(-50%) translateX(-50%);margin:0}.lightbox:target{outline:none;display:block;width:100%;height:100%}.lightbox:target::after{content:'✕';font-size:24px;position:absolute;right:28px;top:26px;color:#efefef;font-family:sans-serif}#disqus_thread{margin-top:40px}.caption{color:#999;font-size:12px;line-height:16px;margin:10px 60px 20px}@media (max-width: 600px){.caption{margin:10px 10px 20px}}.highlight{background:#272822;color:#f8f8f2}.highlight .hll{background-color:#49483e}.highlight .c{color:#75715e}.highlight .k{color:#66d9ef}.highlight .l{color:#ae81ff}.highlight .n{color:#f8f8f2}.highlight .o{color:#f92672}.highlight .p{color:#f8f8f2}.highlight .ch{color:#75715e}.highlight .cm{color:#75715e}.highlight .cp{color:#75715e}.highlight .cpf{color:#75715e}.highlight .c1{color:#75715e}.highlight .cs{color:#75715e}.highlight .gd{color:#f92672}.highlight .ge{font-style:italic}.highlight .gi{color:#a6e22e}.highlight .gs{font-weight:bold}.highlight .gu{color:#75715e}.highlight .kc{color:#66d9ef}.highlight .kd{color:#66d9ef}.highlight .kn{color:#f92672}.highlight .kp{color:#66d9ef}.highlight .kr{color:#66d9ef}.highlight .kt{color:#66d9ef}.highlight .ld{color:#e6db74}.highlight .m{color:#ae81ff}.highlight .s{color:#e6db74}.highlight .na{color:#a6e22e}.highlight .nb{color:#f8f8f2}.highlight .nc{color:#a6e22e}.highlight .no{color:#66d9ef}.highlight .nd{color:#a6e22e}.highlight .ni{color:#f8f8f2}.highlight .ne{color:#a6e22e}.highlight .nf{color:#a6e22e}.highlight .nl{color:#f8f8f2}.highlight .nn{color:#f8f8f2}.highlight .nx{color:#a6e22e}.highlight .py{color:#f8f8f2}.highlight .nt{color:#f92672}.highlight .nv{color:#f8f8f2}.highlight .ow{color:#f92672}.highlight .w{color:#f8f8f2}.highlight .mb{color:#ae81ff}.highlight .mf{color:#ae81ff}.highlight .mh{color:#ae81ff}.highlight .mi{color:#ae81ff}.highlight .mo{color:#ae81ff}.highlight .sa{color:#e6db74}.highlight .sb{color:#e6db74}.highlight .sc{color:#e6db74}.highlight .dl{color:#e6db74}.highlight .sd{color:#e6db74}.highlight .s2{color:#e6db74}.highlight .se{color:#ae81ff}.highlight .sh{color:#e6db74}.highlight .si{color:#e6db74}.highlight .sx{color:#e6db74}.highlight .sr{color:#e6db74}.highlight .s1{color:#e6db74}.highlight .ss{color:#e6db74}.highlight .bp{color:#f8f8f2}.highlight .fm{color:#a6e22e}.highlight .vc{color:#f8f8f2}.highlight .vg{color:#f8f8f2}.highlight .vi{color:#f8f8f2}.highlight .vm{color:#f8f8f2}.highlight .il{color:#ae81ff}.loader{width:80px;height:20px;display:inline-block;text-align:center;white-space:nowrap}.loader .dot{height:20px;width:20px;border-radius:100%;display:inline-block;background:#d53a26;opacity:0;transition:opacity 1s;margin:0 3px;float:left}@-webkit-keyframes fade-dots-0{0%{opacity:0}25%{opacity:1}50%{opacity:0}100%{opacity:0}}@-moz-keyframes fade-dots-0{0%{opacity:0}25%{opacity:1}50%{opacity:0}100%{opacity:0}}@-o-keyframes fade-dots-0{0%{opacity:0}25%{opacity:1}50%{opacity:0}100%{opacity:0}}@keyframes fade-dots-0{0%{opacity:0}25%{opacity:1}50%{opacity:0}100%{opacity:0}}@-webkit-keyframes fade-dots-1{0%{opacity:0}25%{opacity:0}50%{opacity:1}100%{opacity:0}}@-moz-keyframes fade-dots-1{0%{opacity:0}25%{opacity:0}50%{opacity:1}100%{opacity:0}}@-o-keyframes fade-dots-1{0%{opacity:0}25%{opacity:0}50%{opacity:1}100%{opacity:0}}@keyframes fade-dots-1{0%{opacity:0}25%{opacity:0}50%{opacity:1}100%{opacity:0}}@-webkit-keyframes fade-dots-2{0%{opacity:0}25%{opacity:0}50%{opacity:0}100%{opacity:1}}@-moz-keyframes fade-dots-2{0%{opacity:0}25%{opacity:0}50%{opacity:0}100%{opacity:1}}@-o-keyframes fade-dots-2{0%{opacity:0}25%{opacity:0}50%{opacity:0}100%{opacity:1}}@keyframes fade-dots-2{0%{opacity:0}25%{opacity:0}50%{opacity:0}100%{opacity:1}}.loader .dot-0{-webkit-animation:fade-dots-0 1s 0s linear infinite;-moz-animation:fade-dots-0 1s 0s linear infinite;-o-animation:fade-dots-0 1s 0s linear infinite;animation:fade-dots-0 1s 0s linear infinite}.loader .dot-1{-webkit-animation:fade-dots-1 1s 0s linear infinite;-moz-animation:fade-dots-1 1s 0s linear infinite;-o-animation:fade-dots-1 1s 0s linear infinite;animation:fade-dots-1 1s 0s linear infinite}.loader .dot-2{-webkit-animation:fade-dots-2 1s 0s linear infinite;-moz-animation:fade-dots-2 1s 0s linear infinite;-o-animation:fade-dots-2 1s 0s linear infinite;animation:fade-dots-2 1s 0s linear infinite}.lost{position:absolute;top:0;right:0;bottom:0;left:0;overflow:hidden}.lost .message{font-family:'Press Start 2P',cursive;font-size:90px;margin-top:90px;margin-top:22vh;margin-bottom:40px;line-height:90px;color:#6991ab}.lost .return-home{display:inline-block;padding:10px 20px;color:#fff;border-radius:4px;cursor:pointer;font-size:20px;background:#d53a26}@media (max-height: 500px){.lost .return-home{display:none}}.lost .sky{position:absolute;top:0;right:0;bottom:35%;left:0;background:#caf0ff;text-align:center}.lost .cave{position:absolute;bottom:35%;right:-120px;width:500px}.lost .cave-door{position:absolute;bottom:35%;right:0;width:112px;overflow:hidden;z-index:100;height:400px}.lost .cave-right{bottom:0}.lost .cloud{width:250px;position:absolute;right:100px}.lost .grass{width:100%;height:35%;position:absolute;bottom:0;background-color:#3eb96e}.lost .big-grass-patch,.lost .small-grass-patch{position:absolute;width:10px;height:10px}.lost .big-grass-patch:after{content:'';display:block;width:4px;height:4px;background:transparent;box-shadow:4px 10px #1c5437, 8px 6px #1c5437, 12px 10px #1c5437, 16px 6px #1c5437, 20px 10px #1c5437}.lost .small-grass-patch:after{content:'';display:block;width:4px;height:4px;background:transparent;box-shadow:4px 10px #1c5437, 8px 6px #1c5437, 12px 10px #1c5437}.lost .caveman{width:180px;height:180px;position:absolute;bottom:35%;transition:left 0.2s;transform:rotateX(0deg)}.lost .caveman div{width:12px;height:12px;background:transparent;box-shadow:48px 72px #222222, 60px 72px #222222, 72px 72px #222222, 84px 72px #222222, 96px 72px #222222, 36px 84px #171717, 48px 84px #E3BE89, 60px 84px #FBD298, 72px 84px #FBD298, 84px 84px #FBD298, 96px 84px #FBD298, 120px 84px #747269, 36px 96px #E3BE89, 48px 96px #E3BE89, 60px 96px #0E0C09, 72px 96px #FBD298, 84px 96px #FBD298, 96px 96px #0E0C09, 120px 96px #747269, 36px 108px #171717, 48px 108px #E3BE89, 60px 108px #FBD298, 72px 108px #FBD298, 84px 108px #FBD298, 96px 108px #FBD298, 120px 108px #747269, 36px 120px #171717, 48px 120px #171717, 60px 120px #222222, 72px 120px #222222, 84px 120px #222222, 96px 120px #222222, 120px 120px #747269, 24px 132px #A78408, 36px 132px #A78408, 48px 132px #171717, 60px 132px #171717, 72px 132px #171717, 84px 132px #222222, 96px 132px #171717, 108px 132px #A78408, 120px 132px #FBD298, 24px 144px #FBD298, 36px 144px #583617, 48px 144px #71451D, 60px 144px #71451D, 72px 144px #71451D, 84px 144px #5E5650, 96px 144px #71451D, 36px 156px #A78408, 48px 156px #A78408, 60px 156px #A78408, 72px 156px #BF9709, 84px 156px #BF9709, 96px 156px #BF9709, 36px 168px #583617, 96px 168px #71451D}.lost .caveman.charge div{box-shadow:48px 72px #222222, 60px 72px #222222, 72px 72px #222222, 84px 72px #222222, 96px 72px #222222, 156px 72px #747269, 36px 84px #171717, 48px 84px #E3BE89, 60px 84px #FBD298, 72px 84px #FBD298, 84px 84px #FBD298, 96px 84px #FBD298, 144px 84px #747269, 36px 96px #E3BE89, 48px 96px #E3BE89, 60px 96px #0E0C09, 72px 96px #FBD298, 84px 96px #FBD298, 96px 96px #0E0C09, 132px 96px #747269, 36px 108px #171717, 48px 108px #E3BE89, 60px 108px #FBD298, 72px 108px #FBD298, 84px 108px #FBD298, 96px 108px #FBD298, 120px 108px #FBD298, 36px 120px #171717, 48px 120px #171717, 60px 120px #222222, 72px 120px #222222, 84px 120px #222222, 96px 120px #222222, 108px 120px #A78408, 24px 132px #A78408, 36px 132px #A78408, 48px 132px #171717, 60px 132px #171717, 72px 132px #171717, 84px 132px #222222, 96px 132px #171717, 12px 144px #FBD298, 36px 144px #583617, 48px 144px #71451D, 60px 144px #71451D, 72px 144px #71451D, 84px 144px #5E5650, 96px 144px #71451D, 36px 156px #A78408, 48px 156px #A78408, 60px 156px #A78408, 72px 156px #BF9709, 84px 156px #BF9709, 96px 156px #BF9709, 36px 168px #583617, 96px 168px #71451D}@media (max-width: 800px){.lost .cave,.lost .caveman{display:none}}
</style>
    
  
    
    
      <link type="text/css" rel="stylesheet" href="./使用 TensorFlow 识别相似图像_files/similar-images.css">
    
  

    <noscript>This site works best with JavaScript enabled.</noscript>
  <link type="text/css" rel="stylesheet" charset="UTF-8" href="./使用 TensorFlow 识别相似图像_files/m=el_main_css"></head>
  <body>
    <div id="content">
      
  <svg style="width:0px; height:0px;">
    <filter id="header-duotone" color-interpolation-filters="sRGB" x="0" y="0" height="100%" width="100%">
      <fecolormatrix type="matrix" values="0.1640625 0 0 0 0.83203125 0.6953125 0 0 0 0.2265625 0.55078125 0 0 0 0.1484375 0 0 0 1 0"></fecolormatrix>
    </filter>
  </svg>
  <header class="header">
    
      
        <div class="background-image duotone" style="background-image: url(/assets/posts/similar-images/similar-images-banner.jpg)"></div>
      
    
    <div class="home-icon">
  <a href="https://douglasduhaime.com/#">
    <img src="./使用 TensorFlow 识别相似图像_files/home.svg" onerror="this.src=&#39;/assets/images/icons/home.png&#39;" alt="家">
  </a>
</div>
  </header>

<div class="post">
  <div class="container">
    <div class="title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">使用 TensorFlow 识别相似图像</font></font></div>
    <div class="date"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2017 年 8 月 28 日</font></font></div>
    <div class="content"><p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">耶鲁大学数字人文实验室今年的主题是视觉文化。</font><font style="vertical-align: inherit;">我们花了很多时间讨论图像挖掘、颜色分析和相关主题，并对一项特定任务产生了兴趣：识别大型照片集中的相似图像。</font></font></p>

<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">我们在这个主题上的工作始于 Peter Leonard 偶然发现一个</font></font><a href="https://stackoverflow.com/questions/34809795"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">线程</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">，该线程围绕使用 TensorFlow 获取图像的矢量表示。</font><font style="vertical-align: inherit;">该线程的作者指出，通过对 Google 的</font></font><a href="https://www.tensorflow.org/tutorials/image_recognition"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tensorflow 教程</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">之一中的脚本进行小的更改，可以生成可用于各种目的的惊人的图像矢量表示。</font><font style="vertical-align: inherit;">在下文中，我将讨论这一变化，并提出一些关于使用生成的图像向量的方法的想法。</font></font></p>

<h2 id="installing-dependencies"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">安装依赖项</font></font></h2>

<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">首先，我们需要安装 TensorFlow。</font><font style="vertical-align: inherit;">我发现最简单的方法是使用 TensorFlow 的 Anaconda 发行版。</font><font style="vertical-align: inherit;">对于那些不知道的人，Anaconda 是一个非常有用的 Python 发行版，可以轻松管理多个版本的 Python 和 Python 中的各种应用程序依赖项。</font><font style="vertical-align: inherit;">它非常值得安装，所以如果您没有安装</font></font><a href="https://www.continuum.io/downloads"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Anaconda</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">，我会继续安装它。</font></font></p>

<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">安装好 Anaconda 后，您应该能够使用 Python 3.5 创建一个新的虚拟环境，然后使用以下命令在该环境中安装 TensorFlow：</font></font></p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="c"># create virtual environment using python 3.5 with name '3.5'</span>
conda create <span class="nt">-n</span> 3.5 <span class="nv">python</span><span class="o">=</span>3.5<font></font>
<font></font>
<span class="c"># activate the virtual environment</span>
<span class="nb">source </span>activate 3.5<font></font>
<font></font>
<span class="c"># install tensorflow</span>
conda <span class="nb">install</span> <span class="nt">-c</span> conda-forge tensorflow</code></pre></figure>

<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">您应该在终端中看到 (3.5) 作为前言。</font><font style="vertical-align: inherit;">如果你不这样做，那么你就以某种方式离开了名为 3.5 的虚拟环境，因此你需要再次输入“source activate 3.5”重新进入该环境。</font></font></p>

<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">如果您在虚拟环境中并键入“python”，您将进入 Python 解释器。</font><font style="vertical-align: inherit;">在解释器内部，您应该能够通过键入“import tensorflow”来加载 Tensorflow。</font><font style="vertical-align: inherit;">如果没有出现错误，则说明您已经安装了 TensorFlow，并且可以通过键入“quit()”来离开解释器。</font><font style="vertical-align: inherit;">如果确实遇到错误，则需要在继续之前安装 TensorFlow。</font></font></p>

<h2 id="classifying-images-with-tensorflow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">使用 TensorFlow 对图像进行分类</font></font></h2>

<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">下面的代码仅围绕TensorFlow 的 ImageNet 教程中的</font></font><a href="https://github.com/tensorflow/models/blob/master/tutorials/image/imagenet/classify_image.py"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">原始脚本</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">稍作修改。</font><font style="vertical-align: inherit;">原始脚本将单个图像作为输入，并返回图像的多个字符串标签作为输出。</font><font style="vertical-align: inherit;">它旨在从命令行 ala 中使用：</font></font></p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="c"># download the original script</span><font></font>
wget https://raw.githubusercontent.com/tensorflow/models/master/tutorials/image/imagenet/classify_image.py<font></font>
<font></font>
<span class="c"># download a sample image</span>
wget http://thecatapi.com/api/images/get?type<span class="o">=</span>jpg <span class="nt">-O</span> cat.jpg<font></font>
<font></font>
<span class="c"># run the script to generate text labels for an input image</span>
python classify_image.py cat.jpg</code></pre></figure>

<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">第一次运行脚本时，您的机器将下载 Inception，这是一个在 ImageNet 上预训练的卷积神经网络，并在原始论文</font></font><a href="https://arxiv.org/pdf/1409.4842.pdf"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Going Deeper with Convolutions</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">中进行了讨论。</font><font style="vertical-align: inherit;">下载模型后，脚本将向终端打印提供的输入图像的几个标签，每个标签都有一个权重，以显示模型对给定标签的置信度。</font></font></p>

<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">这些标签非常适合增强图像搜索或算法字幕等任务，但它们不一定是测量图像相似性的最佳选择。</font><font style="vertical-align: inherit;">对于相似性任务，与分类标签相比，使用浮点向量通常更好，因为向量捕获更多原始对象的信号。</font></font></p>

<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">令人高兴的是，只需稍微修改 classify_image.py 脚本即可获得图像的矢量表示。</font><font style="vertical-align: inherit;">本质上，我们不会向神经网络的最后（softmax）层询问输入图像的文本分类，而是向神经网络的倒数第二层询问给定图像的内部模型权重，我们将存储这些权重作为输入图像的向量表示。</font><font style="vertical-align: inherit;">这将使我们能够使用图像执行传统的矢量分析。</font></font></p>

<h2 id="vectorizing-images-with-tensorflow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">使用 TensorFlow 对图像进行矢量化</font></font></h2>

<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">原始的 classify_image.py 调用了一个方法“run_inference_on_image()”来处理输入图像的图像分类。</font><font style="vertical-align: inherit;">这是该方法：</font></font></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">run_inference_on_image</span><span class="p">(</span><span class="n">image</span><span class="p">):</span>
  <span class="s">"""Runs inference on an image.

  Args:
    image: Image file name.

  Returns:
    Nothing
  """</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="n">tf</span><span class="o">.</span><span class="n">gfile</span><span class="o">.</span><span class="n">Exists</span><span class="p">(</span><span class="n">image</span><span class="p">):</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">fatal</span><span class="p">(</span><span class="s">'File does not exist </span><span class="si">%</span><span class="s">s'</span><span class="p">,</span> <span class="n">image</span><span class="p">)</span>
  <span class="n">image_data</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gfile</span><span class="o">.</span><span class="n">FastGFile</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="s">'rb'</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span><font></font>
<font></font>
  <span class="c1"># Creates graph from saved GraphDef.
</span>  <span class="n">create_graph</span><span class="p">()</span><font></font>
<font></font>
  <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="c1"># Some useful tensors:
</span>    <span class="c1"># 'softmax:0': A tensor containing the normalized prediction across
</span>    <span class="c1">#   1000 labels.
</span>    <span class="c1"># 'pool_3:0': A tensor containing the next-to-last layer containing 2048
</span>    <span class="c1">#   float description of the image.
</span>    <span class="c1"># 'DecodeJpeg/contents:0': A tensor containing a string providing JPEG
</span>    <span class="c1">#   encoding of the image.
</span>    <span class="c1"># Runs the softmax tensor by feeding the image_data as input to the graph.
</span>    <span class="n">softmax_tensor</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s">'softmax:0'</span><span class="p">)</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">softmax_tensor</span><span class="p">,</span>
                           <span class="p">{</span><span class="s">'DecodeJpeg/contents:0'</span><span class="p">:</span> <span class="n">image_data</span><span class="p">})</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span><font></font>
<font></font>
    <span class="c1"># Creates node ID --&gt; English string lookup.
</span>    <span class="n">node_lookup</span> <span class="o">=</span> <span class="n">NodeLookup</span><span class="p">()</span><font></font>
<font></font>
    <span class="n">top_k</span> <span class="o">=</span> <span class="n">predictions</span><span class="o">.</span><span class="n">argsort</span><span class="p">()[</span><span class="o">-</span><span class="n">FLAGS</span><span class="o">.</span><span class="n">num_top_predictions</span><span class="p">:][::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">node_id</span> <span class="ow">in</span> <span class="n">top_k</span><span class="p">:</span>
      <span class="n">human_string</span> <span class="o">=</span> <span class="n">node_lookup</span><span class="o">.</span><span class="n">id_to_string</span><span class="p">(</span><span class="n">node_id</span><span class="p">)</span>
      <span class="n">score</span> <span class="o">=</span> <span class="n">predictions</span><span class="p">[</span><span class="n">node_id</span><span class="p">]</span>
      <span class="k">print</span><span class="p">(</span><span class="s">'</span><span class="si">%</span><span class="s">s (score = </span><span class="si">%.5</span><span class="s">f)'</span> <span class="o">%</span> <span class="p">(</span><span class="n">human_string</span><span class="p">,</span> <span class="n">score</span><span class="p">))</span></code></pre></figure>

<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">此方法指出张量 pool_3:0 包含网络倒数第二层的权重。</font><font style="vertical-align: inherit;">这些权重形成一个 2048 维向量（或 2048 个数字单元的列表），非常适合图像相似性计算。</font><font style="vertical-align: inherit;">除了网络的最后一层之外，让我们抓住该层：</font></font></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">run_inference_on_images</span><span class="p">(</span><span class="n">image_list</span><span class="p">,</span> <span class="n">output_dir</span><span class="p">):</span>
  <span class="s">"""Runs inference on an image list.
  Args:
    image_list: {list} a list of paths to image files
    output_dir: {string} name of the directory where image vectors will be saved
  Returns:
    image_to_labels: {dict} a dictionary with image file keys and predicted
      text label values
  """</span>
  <span class="n">image_to_labels</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span><font></font>
<font></font>
  <span class="n">create_graph</span><span class="p">()</span><font></font>
<font></font>
  <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="c1"># Some useful tensors:
</span>    <span class="c1"># 'softmax:0': A tensor containing the normalized prediction across
</span>    <span class="c1">#   1000 labels.
</span>    <span class="c1"># 'pool_3:0': A tensor containing the next-to-last layer containing 2048
</span>    <span class="c1">#   float description of the image.
</span>    <span class="c1"># 'DecodeJpeg/contents:0': A tensor containing a string providing JPEG
</span>    <span class="c1">#   encoding of the image.
</span>    <span class="c1"># Runs the softmax tensor by feeding the image_data as input to the graph.
</span>    <span class="n">softmax_tensor</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s">'softmax:0'</span><span class="p">)</span><font></font>
<font></font>
    <span class="k">for</span> <span class="n">image_index</span><span class="p">,</span> <span class="n">image</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">image_list</span><span class="p">):</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"parsing"</span><span class="p">,</span> <span class="n">image_index</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="s">"</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">tf</span><span class="o">.</span><span class="n">gfile</span><span class="o">.</span><span class="n">Exists</span><span class="p">(</span><span class="n">image</span><span class="p">):</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">fatal</span><span class="p">(</span><span class="s">'File does not exist </span><span class="si">%</span><span class="s">s'</span><span class="p">,</span> <span class="n">image</span><span class="p">)</span><font></font>
<font></font>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">gfile</span><span class="o">.</span><span class="n">FastGFile</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="s">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
          <span class="n">image_data</span> <span class="o">=</span>  <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span><font></font>
<font></font>
          <span class="n">predictions</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">softmax_tensor</span><span class="p">,</span>
                          <span class="p">{</span><span class="s">'DecodeJpeg/contents:0'</span><span class="p">:</span> <span class="n">image_data</span><span class="p">})</span><font></font>
<font></font>
          <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span><font></font>
<font></font>
          <span class="c1">##
</span>          <span class="c1"># Get penultimate layer weights
</span>          <span class="c1">##
</span>
          <span class="n">feature_tensor</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s">'pool_3:0'</span><span class="p">)</span>
          <span class="n">feature_set</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">feature_tensor</span><span class="p">,</span>
                          <span class="p">{</span><span class="s">'DecodeJpeg/contents:0'</span><span class="p">:</span> <span class="n">image_data</span><span class="p">})</span>
          <span class="n">feature_vector</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">feature_set</span><span class="p">)</span>
          <span class="n">outfile_name</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">image</span><span class="p">)</span> <span class="o">+</span> <span class="s">".npz"</span>
          <span class="n">out_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="n">outfile_name</span><span class="p">)</span>
          <span class="n">np</span><span class="o">.</span><span class="n">savetxt</span><span class="p">(</span><span class="n">out_path</span><span class="p">,</span> <span class="n">feature_vector</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s">','</span><span class="p">)</span><font></font>
<font></font>
          <span class="c1">##
</span>          <span class="c1"># Store softmax classification results
</span>          <span class="c1">##
</span>
          <span class="c1"># Creates node ID --&gt; English string lookup.
</span>          <span class="n">node_lookup</span> <span class="o">=</span> <span class="n">NodeLookup</span><span class="p">()</span><font></font>
<font></font>
          <span class="n">top_k</span> <span class="o">=</span> <span class="n">predictions</span><span class="o">.</span><span class="n">argsort</span><span class="p">()[</span><span class="o">-</span><span class="n">FLAGS</span><span class="o">.</span><span class="n">num_top_predictions</span><span class="p">:][::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
          <span class="k">for</span> <span class="n">node_id</span> <span class="ow">in</span> <span class="n">top_k</span><span class="p">:</span>
            <span class="n">human_string</span> <span class="o">=</span> <span class="n">node_lookup</span><span class="o">.</span><span class="n">id_to_string</span><span class="p">(</span><span class="n">node_id</span><span class="p">)</span>
            <span class="n">score</span> <span class="o">=</span> <span class="n">predictions</span><span class="p">[</span><span class="n">node_id</span><span class="p">]</span><font></font>
<font></font>
            <span class="n">image_to_labels</span><span class="p">[</span><span class="n">image</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
              <span class="s">"labels"</span><span class="p">:</span> <span class="n">human_string</span><span class="p">,</span>
              <span class="s">"score"</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
            <span class="p">})</span><font></font>
<font></font>
        <span class="c1"># close the open file handlers
</span>        <span class="n">proc</span> <span class="o">=</span> <span class="n">psutil</span><span class="o">.</span><span class="n">Process</span><span class="p">()</span>
        <span class="n">open_files</span> <span class="o">=</span> <span class="n">proc</span><span class="o">.</span><span class="n">open_files</span><span class="p">()</span><font></font>
<font></font>
        <span class="k">for</span> <span class="n">open_file</span> <span class="ow">in</span> <span class="n">open_files</span><span class="p">:</span>
          <span class="n">file_handler</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">open_file</span><span class="p">,</span> <span class="s">"fd"</span><span class="p">)</span>
          <span class="n">os</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="n">file_handler</span><span class="p">)</span>
      <span class="k">except</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s">'could not process image index'</span><span class="p">,</span><span class="n">image_index</span><span class="p">,</span><span class="s">'image'</span><span class="p">,</span> <span class="n">image</span><span class="p">)</span><font></font>
<font></font>
  <span class="k">return</span> <span class="n">image_to_labels</span></code></pre></figure>

<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">在这里，我们看到了我们将对 run_inference_on_image() 进行的修改。</font><font style="vertical-align: inherit;">他们专注于处理一系列输入图像，对每个图像使用错误处理以防 png 文件或 jp2 偷偷进入我们的 jpeg 集合，最重要的是捕获和保存神经网络的倒数第二层。</font></font></p>

<h2 id="finding-similar-images"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">查找相似图像</font></font></h2>

<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">要识别大型图像集合中的相似图像，可以运行以下行来下载完整更新的分类图像脚本，安装 psutil（用于管理打开的文件处理程序），然后在充满图像的目录上运行更新的脚本：</font></font></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># get the full updated script
</span><span class="n">wget</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">gist</span><span class="o">.</span><span class="n">githubusercontent</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">duhaime</span><span class="o">/</span><span class="mi">2</span><span class="n">a71921c9f4655c96857dbb6b6ed9bd6</span><span class="o">/</span><span class="n">raw</span><span class="o">/</span><span class="mf">0e72</span><span class="n">c48e698395265d029fabad0e6ab1f3961b26</span><span class="o">/</span><span class="n">classify_images</span><span class="o">.</span><span class="n">py</span><font></font>
<font></font>
<span class="c1"># install the new dependency inside your virtual environment
</span><span class="n">pip</span> <span class="n">install</span> <span class="n">psutil</span><font></font>
<font></font>
<span class="c1"># download a collection of jpg images (or use one you have)
</span><span class="n">wget</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">goo</span><span class="o">.</span><span class="n">gl</span><span class="o">/</span><span class="n">Lf9vmN</span> <span class="o">-</span><span class="n">O</span> <span class="n">images</span><span class="o">.</span><span class="n">tar</span><span class="o">.</span><span class="n">gz</span>
<span class="n">tar</span> <span class="o">-</span><span class="n">zxf</span> <span class="n">images</span><span class="o">.</span><span class="n">tar</span><span class="o">.</span><span class="n">gz</span><font></font>
<font></font>
<span class="c1"># run the script on a glob of images
</span><span class="n">python</span> <span class="n">classify_images</span><span class="o">.</span><span class="n">py</span> <span class="s">"images/*"</span></code></pre></figure>

<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">这将生成一个新目录“image_vectors”，并将为该目录中的每个输入图像创建一个向量，使用输入图像名称作为输出向量名称的根。</font></font></p>

<h2 id="finding-nearest-neighbors"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">寻找最近的邻居</font></font></h2>

<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">上面 classify_images.py 的修改版本为每个输入图像生成一个图像向量。</font><font style="vertical-align: inherit;">有了这些向量，就可以运行后续分析以获得不同的效果。</font><font style="vertical-align: inherit;">例如，假设您想要为每个输入图像找到最相似的图像。</font><font style="vertical-align: inherit;">下面的浏览器提供了此类功能的一个示例：</font></font></p>

<div class="nearest-neighbors">
  <button><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">刷新</font></font></button>
  <div class="random masonry-container"><div class="image-cell-container" style="opacity: 0.4;"><div class="background-image image-cell" style="background-image: url(&quot;https://s3.amazonaws.com/duhaime/blog/image-similarity/images/4000123.jpg&quot;);"></div></div><div class="image-cell-container" style="opacity: 0.4;"><div class="background-image image-cell" style="background-image: url(&quot;https://s3.amazonaws.com/duhaime/blog/image-similarity/images/3999941.jpg&quot;);"></div></div><div class="image-cell-container" style="opacity: 0.4;"><div class="background-image image-cell" style="background-image: url(&quot;https://s3.amazonaws.com/duhaime/blog/image-similarity/images/4000375.jpg&quot;);"></div></div><div class="image-cell-container" style="opacity: 1;"><div class="background-image image-cell" style="background-image: url(&quot;https://s3.amazonaws.com/duhaime/blog/image-similarity/images/3999713.jpg&quot;);"></div></div><div class="image-cell-container" style="opacity: 0.4;"><div class="background-image image-cell" style="background-image: url(&quot;https://s3.amazonaws.com/duhaime/blog/image-similarity/images/3999855.jpg&quot;);"></div></div><div class="image-cell-container" style="opacity: 0.4;"><div class="background-image image-cell" style="background-image: url(&quot;https://s3.amazonaws.com/duhaime/blog/image-similarity/images/3999687.jpg&quot;);"></div></div><div class="image-cell-container" style="opacity: 0.4;"><div class="background-image image-cell" style="background-image: url(&quot;https://s3.amazonaws.com/duhaime/blog/image-similarity/images/4000501.jpg&quot;);"></div></div><div class="image-cell-container" style="opacity: 0.4;"><div class="background-image image-cell" style="background-image: url(&quot;https://s3.amazonaws.com/duhaime/blog/image-similarity/images/1952301.jpg&quot;);"></div></div><div class="image-cell-container" style="opacity: 0.4;"><div class="background-image image-cell" style="background-image: url(&quot;https://s3.amazonaws.com/duhaime/blog/image-similarity/images/3999889.jpg&quot;);"></div></div><div class="image-cell-container" style="opacity: 0.4;"><div class="background-image image-cell" style="background-image: url(&quot;https://s3.amazonaws.com/duhaime/blog/image-similarity/images/3999857.jpg&quot;);"></div></div></div>
  <div class="matches masonry-container">
    <div class="guide" style="display: none;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">将鼠标悬停在图像上</font></font></div>
  <div class="image-cell-container"><div class="background-image image-cell" style="background-image: url(&quot;https://s3.amazonaws.com/duhaime/blog/image-similarity/images/3999713.jpg&quot;);"></div></div><div class="image-cell-container"><div class="background-image image-cell" style="background-image: url(&quot;https://s3.amazonaws.com/duhaime/blog/image-similarity/images/3999717.jpg&quot;);"></div></div><div class="image-cell-container"><div class="background-image image-cell" style="background-image: url(&quot;https://s3.amazonaws.com/duhaime/blog/image-similarity/images/3999723.jpg&quot;);"></div></div><div class="image-cell-container"><div class="background-image image-cell" style="background-image: url(&quot;https://s3.amazonaws.com/duhaime/blog/image-similarity/images/3999715.jpg&quot;);"></div></div><div class="image-cell-container"><div class="background-image image-cell" style="background-image: url(&quot;https://s3.amazonaws.com/duhaime/blog/image-similarity/images/3999721.jpg&quot;);"></div></div></div>
</div>
<div class="clear-both"></div>

<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">实现此功能的一个好方法是利用 Erik Bern 的近似最近邻 Oh Yeah</font></font><a href="https://github.com/spotify/annoy"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">库</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">来识别每个图像的近似最近邻。</font><font style="vertical-align: inherit;">上面的相似图像查看器使用 ANN 来识别相似图像 [我使用了这个</font></font><a href="https://douglasduhaime.com/assets/posts/similar-images/utils/cluster_vectors.py"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">最近的邻居脚本</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">]。</font><font style="vertical-align: inherit;">为了识别我们上面创建的图像向量的最近邻居，可以运行：</font></font></p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">wget http://douglasduhaime.com/assets/posts/similar-images/utils/cluster_vectors.py<font></font>
pip <span class="nb">install </span>annoy <span class="o">&amp;&amp;</span> pip <span class="nb">install </span>scipy <span class="o">&amp;&amp;</span> pip <span class="nb">install </span>nltk<font></font>
python cluster_vectors.py</code></pre></figure>

<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">这些命令将生成一个以您当前工作目录命名的目录</font></font><code class="highlighter-rouge">nearest_neighbors</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">，并将为集合中的每个图像创建一个输出文件。</font><font style="vertical-align: inherit;">这些输出文件中的每一个都将识别出与给定图像最相似的 30 张图像。</font><font style="vertical-align: inherit;">要搜索更多或更少的最近邻居，只需更新</font></font><code class="highlighter-rouge">n_nearest_neighbors</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">最近邻居脚本中的变量。</font></font></p>

<h2 id="image-tsne-projections"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">图像 TSNE 投影</font></font></h2>

<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">图像矢量的另一个有趣应用是 TSNE 投影。</font><font style="vertical-align: inherit;">如果您以前没有使用过 TSNE，它本质上是一种降维技术，在某些方面类似于主成分分析，除了它针对学习和保留高维数据集中的非线性模式进行了优化。</font><font style="vertical-align: inherit;">TSNE 投影经常用于数据可视化，因为即使在二维投影中，它们也能使相似的高维向量彼此相邻出现。</font></font></p>

<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">如果我们将所有图像向量加载到 TSNE 模型中，然后将数据向下两个维度投影，我们可以创建图像集合的二维表示，以保留图像之间的相似性。</font><font style="vertical-align: inherit;">在这种数据表示中，每个图像都位于与其最相似的图像附近（单击以查看交互式视图）：</font></font></p>

<p><a href="https://douglasduhaime.com/pages/tsne-images/index.html" class="click-to-interact">
  <img src="./使用 TensorFlow 识别相似图像_files/tsne-images.jpg" alt="纽约公共图书馆收藏的 Works Progress Administration 照片中的相似图像的 TSNE 投影">
</a></p>

<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">该图本身是使用本机 HTML5 画布方法生成的，但 D3.js 有助于提供数据获取、DOM 操作和 Voronoi 鼠标悬停图。</font><font style="vertical-align: inherit;">该图的数据是由这个</font></font><a href="https://douglasduhaime.com/assets/posts/similar-images/utils/get_tsne_vector_projections.py"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tsne 聚类脚本</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">生成的。</font></font></p>
</div>
  </div>
</div>
<footer class="footer">
  
  <a target="_blank" href="http://github.com/duhaime">
    <img class="footer-icon" src="./使用 TensorFlow 识别相似图像_files/github-dark.svg" onerror="this.src=&#39;/assets/images/icons/github-dark.png&#39;" alt="GitHub 图标">
</a>
<a target="_blank" href="http://bl.ocks.org/duhaime">
  <div class="footer-icon square-image">
      <img src="./使用 TensorFlow 识别相似图像_files/blocks-dark.svg" onerror="this.src=&#39;/assets/images/icons/blocks-dark.png&#39;" alt="方块图标">
    
  </div>
</a>
<a target="_blank" href="http://twitter.com/douglasduhaime">
    <img class="footer-icon" src="./使用 TensorFlow 识别相似图像_files/twitter-dark.svg" onerror="this.src=&#39;/assets/images/icons/twitter-dark.png&#39;" alt="推特图标">
</a>
<a target="_blank" href="https://douglasduhaime.com/feed.xml">
  <div class="footer-icon square-image">
      <img src="./使用 TensorFlow 识别相似图像_files/rss-dark.svg" onerror="this.src=&#39;/assets/images/icons/rss-dark.png&#39;" alt="RSS图标">
  </div>
</a>
</footer>

    </div>
    <script>;(function() {

  window.lightbox = function(selector, imgs) {
    var container = document.querySelector(selector);

    for (var i=0; i<imgs.length; i++) {

      // create default displayed image container - links to the larger img
      var thumb = document.createElement('a'),
          hash = 'lb-' + parseInt(Math.random() * 2**32);
      thumb.className = 'default-image';
      thumb.href = '#' + hash;

      // create the image within that container
      var img = document.createElement('img');
      img.src = imgs[i];
      img.alt = 'lightbox-displayed';
      thumb.appendChild(img);

      // create the larger lightbox image container
      var box = document.createElement('a');
      box.href = '#_';
      box.className = 'lightbox';
      box.id = hash;

      // create the lightbox image inside that container
      var larger = document.createElement('img');
      larger.src = imgs[i];
      larger.alt = 'lightbox large image';
      box.appendChild(larger);

      // add the children components
      container.appendChild(thumb);
      container.appendChild(box);
    }
  }

})();
;(function() {
  function convertToDuotone(container, color1, color2) {
    if (!container) return;
    var matrix = container.querySelector('feColorMatrix');
    var value = [];
    value = value.concat(
    [color1[0]/256 - color2[0]/256, 0, 0, 0, color2[0]/256]);
    value = value.concat(
    [color1[1]/256 - color2[1]/256, 0, 0, 0, color2[1]/256]);
    value = value.concat(
    [color1[2]/256 - color2[2]/256, 0, 0, 0, color2[2]/256]);
    value = value.concat([0, 0, 0, 1, 0]);
    matrix.setAttribute('values', value.join(' '));
  }

  var header = document.getElementById('header-duotone');
  convertToDuotone(header, [255, 236, 179], [213, 58, 38]);
})();
;(function() {

  /**
  * Draw the grass
  **/

  var grass = document.querySelector('.grass');
  if (!grass) return;

  var width = grass.offsetWidth - 20;
  var height = grass.offsetHeight - 20;

  function getRandomInt(min, max) {
    return Math.floor(Math.random() * (max - min + 1)) + min;
  }

  function getElem(className) {
    var marginTop = getRandomInt(0, height);
    var marginLeft = getRandomInt(0, width);
    var cssText = 'left:' + marginLeft + 'px;';
    cssText += 'top:' + marginTop + 'px;';

    var elem = document.createElement('div');
    elem.className = className;
    elem.style.cssText = cssText;
    return elem;
  }

  ['small-grass-patch', 'large-grass-patch'].forEach(function(d) {
    for (var i=0; i<10; i++) {
      var elem = getElem(d);
      grass.appendChild(elem);
    }
  })

  /**
  * Let the caveman run
  **/

  function handleKeys(e) {
    if (e.keyCode == 39) run(+150);
    if (e.keyCode == 37) run(-150);
  }

  function run(val) {
    var left = parseInt(caveman.style.left, 10)

    // if the caveman enters the cave, return home
    if (left + val > width) returnHome();

    // else make him run and change direction
    caveman.style.left = left + val + 'px';
    caveman.style.transform = val > 0 ? 'rotateY(0deg)' : 'rotateY(180deg)'
    if (!caveman.className.includes('charge')) {
      caveman.className += ' charge';
    }
  }

  var body = document.querySelector('body');
  var caveman = document.querySelector('.caveman');
  body.addEventListener('keydown', handleKeys)

  /**
  * Send users home
  **/

  function returnHome() {
    window.location = '/#'
  }

  var homeButton = document.querySelector('.return-home');
  homeButton.addEventListener('click', returnHome)

})();
;(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-101732875-1', 'auto');
ga('send', 'pageview');</script>
    
  
    
      
      
        <script type="text/javascript" src="./使用 TensorFlow 识别相似图像_files/lodash.min.js"></script>
      
    
      
      
        <script type="text/javascript" src="./使用 TensorFlow 识别相似图像_files/d3.min.js"></script>
      
    
      
      
        <script type="text/javascript" src="./使用 TensorFlow 识别相似图像_files/similar-images.js"></script><div id="goog-gt-" class="skiptranslate VIpgJd-yAWNEb-L7lbkb" dir="ltr"><div style="padding: 8px;"><div><div class="VIpgJd-yAWNEb-l4eHX"><img src="./使用 TensorFlow 识别相似图像_files/translate_24dp.png" width="20" height="20" alt="Google 翻译"></div></div></div><div style="padding: 8px; float: left; width: 100%;"><h1 class="VIpgJd-yAWNEb-r4nke VIpgJd-yAWNEb-mrxPge">原文</h1></div><div style="padding: 8px;"><div class="VIpgJd-yAWNEb-nVMfcd-fmcmS"></div></div><div class="VIpgJd-yAWNEb-cGMI2b" style="padding: 8px;"><div class="VIpgJd-yAWNEb-Z0Arqf-PLDbbf"><span class="VIpgJd-yAWNEb-Z0Arqf-hSRGPd">提供更好的翻译建议</span></div><div class="VIpgJd-yAWNEb-fw42Ze-Z0Arqf-haAclf"><hr style="color: #ccc; background-color: #ccc; height: 1px; border: none;"><div class="VIpgJd-yAWNEb-Z0Arqf-H9tDt"></div></div></div><div class="VIpgJd-yAWNEb-jOfkMb-Ne3sFf" style="display: none;"></div></div>
      
    
  

  
</body></html>